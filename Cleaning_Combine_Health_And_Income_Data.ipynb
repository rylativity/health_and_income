{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "from uszipcode import SearchEngine\n",
    "import numpy as np\n",
    "from progressbar import ProgressBar\n",
    "import math\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District \", \"of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### NOTE: You must unzip the 500 Cities Dataset first before reading it in with this line\n",
    "raw_health = pd.read_csv(\"./sourcedata/500_Cities__Local_Data_for_Better_Health__2017_release.csv\")\n",
    "raw_metro_income = pd.read_csv('./sourcedata/metropolitan_income_data.csv')\n",
    "raw_county_income = pd.read_csv(\"./sourcedata/county_income.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean County Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_county_income.dropna(how=\"all\",inplace=True)\n",
    "raw_county_income.dropna(subset=[\"2017\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_county_income[\"Rank_In_State_2018\"] = raw_county_income[\"Rank_In_State_2018\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_county_income.reset_index(drop=True, inplace=True)\n",
    "raw_county_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to reformat raw_county_income which has both states and counties listed in rows\n",
    "counties_dicts = []\n",
    "for i in range(raw_county_income.shape[0]):\n",
    "    if raw_county_income[\"Rank_In_State_2018\"][i] == 0: #if ==0, it is the state, not a county\n",
    "        state_name = raw_county_income[\"County_Or_State\"][i]\n",
    "    else:\n",
    "        county_dict = {\"city_county\":raw_county_income[\"County_Or_State\"][i],\n",
    "                       \"state\":state_name,\n",
    "                       \"2017\":raw_county_income[\"2017\"][i],\n",
    "                      \"Rank_In_State_2018\":raw_county_income[\"Rank_In_State_2018\"][i]}\n",
    "        counties_dicts.append(county_dict)\n",
    "    if(i == raw_county_income.shape[0]-1) or (raw_county_income[\"Rank_In_State_2018\"][i+1] == 0):\n",
    "        counties_dicts.append(county_dict)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "county_income_df = pd.DataFrame(counties_dicts, index=range(len(counties_dicts)))\n",
    "county_income_df[\"type\"] = [\"county\" for i in range(county_income_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_income_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Metro (City) Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_metro_income.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metro_income[\"city_county\"] = [i.split(\",\")[0] for i in raw_metro_income[\"Metro_Area\"]]\n",
    "raw_metro_income[\"state\"] = [i.split(\",\")[1].strip() for i in raw_metro_income[\"Metro_Area\"]]\n",
    "raw_metro_income.drop([\"Metro_Area\",\"2016\",\"2018\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metro_income[\"type\"] = [\"city\" for i in range(raw_metro_income.shape[0])]\n",
    "raw_metro_income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine County and Metro(City) Income DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.concat([raw_metro_income, county_income_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.reset_index(drop=True, inplace=True)\n",
    "print(income.shape)\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Zipcodes for income data by city and state\n",
    "def get_zipcode_by_city_state(city:str, state:str, search_engine=None) -> str:\n",
    "    if search_engine == None:\n",
    "        search_engine = SearchEngine(simple_zipcode=True)\n",
    "    try:\n",
    "        zips = search_engine.by_city_and_state(city, state)\n",
    "        return zips.zipcode\n",
    "    except AttributeError:\n",
    "        return \",\".join([z.zipcode for z in zips]) \n",
    "    except KeyError:\n",
    "        return \"NotFound\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_engine = SearchEngine(simple_zipcode=True)\n",
    "zipcodes = []\n",
    "for row in range(income.shape[0]):\n",
    "    zipcode = get_zipcode_by_city_state(income[\"city_county\"][row], income[\"state\"][row], search_engine)\n",
    "    zipcodes.append(zipcode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income[\"zips\"] = zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income.to_csv(\"./processeddata/income_city_county_zipcode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_health[\"GeographicLevel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = raw_health[raw_health[\"GeographicLevel\"] == \"US\"]\n",
    "# cities = raw_health[raw_health[\"GeographicLevel\"] == \"City\"]\n",
    "census_tracts = raw_health[raw_health[\"GeographicLevel\"] == \"Census Tract\"]\n",
    "census_tracts.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tracts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of a Geolocation from the Data\n",
    "census_tracts.GeoLocation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create latitude and longitude cols from GeoLocation\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "for row in census_tracts[\"GeoLocation\"]:\n",
    "    swap = str(row)\n",
    "    swap = swap.replace(\"(\",\"\").replace(\")\",\"\").split(\",\")\n",
    "    lat, long = swap[0], swap[1].strip()\n",
    "    latitudes.append(lat)\n",
    "    longitudes.append(long)\n",
    "census_tracts[\"latitude\"] = latitudes\n",
    "census_tracts[\"longitude\"] = longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health data is structured odd, need to create a list of the various measures tracked in the dataset\n",
    "measures = list(census_tracts.Measure.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These are each of the measures in the data, will have to reformat the data\n",
    "print(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary to link metric abbreviations to meanings\n",
    "measure_abbvs = list(census_tracts.MeasureId.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dictionary = {}\n",
    "for abbv in measure_abbvs:\n",
    "    meaning = census_tracts.loc[census_tracts[\"MeasureId\"] == abbv].head(1)[\"Measure\"].values[0]\n",
    "    measure_dictionary[abbv] = meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the measure meanings dictionary to a json file for use during modeling and exploration\n",
    "with open(\"./processeddata/measure_meanings.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(measure_dictionary,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making a separate df for each measure\n",
    "census_measures_dfs = [census_tracts[census_tracts[\"Measure\"] == measure] for measure in measures] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "census_measures_dfs[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit of reformatting of our dataframes, which will be merged together into a master df\n",
    "metric_dfs = []\n",
    "for df in census_measures_dfs:\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    temp = pd.DataFrame({df.MeasureId[0]:df.Data_Value, # this is the actual value for the measure\n",
    "                         \"UniqueID\":df.UniqueID,\"geometry\":df.GeoLocation, # UniqueID and geolocation cols\n",
    "                         \"state\":df.StateAbbr, \"city_county\":df.CityName,\n",
    "                         \"longitude\": df.longitude, \"latitude\":df.latitude,\n",
    "                        \"tract_pop_count\":df.PopulationCount})\n",
    "    metric_dfs.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_dfs[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master DF of all metrics dfs\n",
    "census_health = pd.merge(metric_dfs[0],metric_dfs[1], how='left',on=\"UniqueID\") \n",
    "for i in metric_dfs[2:]: # merging the rest with a for loop\n",
    "    census_health = census_health.merge(i, how = \"left\",on=\"UniqueID\")\n",
    "census_health.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(census_health.columns)\n",
    "for col in cols:\n",
    "    if col.endswith(\"_y\"):\n",
    "        census_health.drop(col, axis = 1, inplace = True)\n",
    "    elif col.endswith(\"_x\"):\n",
    "        census_health.rename({col:col.replace(\"_x\",\"\")}, axis=1, inplace = True)\n",
    "\n",
    "census_health = census_health.loc[:,~census_health.columns.duplicated()] # remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add zip codes to census tracts based\n",
    "def get_zipcode_by_lat_long(lat:str, long:str, radius=25, search_engine=None) -> str:\n",
    "    if search_engine == None:\n",
    "        search_engine = SearchEngine(simple_zipcode=True)\n",
    "    try:\n",
    "        zips = search_engine.by_coordinates(float(lat), float(long),radius, returns=1)#only taking best hit on zip, lat long should be precise enough for 1 zip\n",
    "        return zips.zipcode\n",
    "    except AttributeError:\n",
    "        return \",\".join([z.zipcode for z in zips]) \n",
    "    except KeyError:\n",
    "        return \"NotFound\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = SearchEngine(simple_zipcode=True)\n",
    "zipcodes = []\n",
    "for row in range(census_health.shape[0]):\n",
    "    zipcode = get_zipcode_by_lat_long(census_health[\"latitude\"][row], census_health[\"longitude\"][row], search_engine = search_engine)\n",
    "    zipcodes.append(zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_health[\"zips\"] = zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "census_health.to_csv(\"./processeddata/census_health_data_zipcode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Health And Income Data On Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv(\"./processeddata/income_city_county_zipcode.csv\", dtype = {\"zips\":str})\n",
    "census_health = pd.read_csv(\"./processeddata/census_health_data_zipcode.csv\", dtype = {\"zips\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.drop([\"Unnamed: 0\",\"city_county\",\"state\"], axis=1, inplace=True)\n",
    "income.dropna(subset=[\"zips\"], inplace=True)\n",
    "\n",
    "census_health.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "census_health.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zipcodes not identified for 1037 counties/cities\n",
    "income[\"zips\"].isna().sum(), income.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_zipcodes = [str(i) for i in census_health[\"zips\"].value_counts().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar = ProgressBar()\n",
    "\n",
    "# Create income lookup dict from income df\n",
    "median_income_2017 = {}\n",
    "for zipcode in bar(census_health[\"zips\"].value_counts().index):\n",
    "\n",
    "    filtered_df = income[income[\"zips\"].str.contains(str(zipcode))] \n",
    "    \n",
    "    swap_income = [int(val) for val in filtered_df[\"2017\"].values if not math.isnan(val)] #might hit on multiple zips\n",
    "    mean_of_median_incs = np.mean(swap_income)\n",
    "    median_income_2017[str(zipcode)] = mean_of_median_incs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bar = ProgressBar()\n",
    "\n",
    "census_health[\"Median_Income_2017\"] = [np.NaN for i in range(census_health.shape[0])]\n",
    "for zipcode, inc in bar(median_income_2017.items()):\n",
    "    census_health.loc[census_health[\"zips\"] == zipcode, \"Median_Income_2017\"] = inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need more precise income data as a lot of zipcodes don't have income data, may want to impute based on closest locs\n",
    "census_health.Median_Income_2017.isna().sum(), census_health.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_health.to_csv(\"./processeddata/census_health_citycounty_income_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
